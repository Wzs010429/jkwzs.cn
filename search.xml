<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Vue3背景认识和面试点</title>
      <link href="/2022/02/22/Vue3%E8%83%8C%E6%99%AF%E8%AE%A4%E8%AF%86%E5%92%8C%E9%9D%A2%E8%AF%95%E7%82%B9/"/>
      <url>/2022/02/22/Vue3%E8%83%8C%E6%99%AF%E8%AE%A4%E8%AF%86%E5%92%8C%E9%9D%A2%E8%AF%95%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<h1>Web前端技术发展</h1><p>早期的Web应用主要是以静态页面的浏览（比如新闻浏览），这些静态页面使用HTML语音编写。1995 年，Netseape 公司的工程师 Brendan Eich 设计了JavaScript 脚本语言，使前端网页具有动态的效果（跑马灯，浮动广告等），以及与用户交互能力的表单。</p><p>然而随着互联网的发展，很多的线下业务的开始向向上发展。基于 Internet 的 Web 应用也变越复杂，用户所访詞的资源已不仅仅局限于服务器硬盘上存放的静态网页，更多的应用需要根据户的请求动态生成页面信息，复杂一些的还需要从数据库中查询数据，经过一定的运算，生成一个页面返回给用户。</p><ul><li>1996 年，微软公司推出了 ASP 技术；</li><li>1997年，Sun 公司推出了 JSP技术；</li><li>1998年6月，PHP 3 正式发布</li></ul><p>由此网页开启了真正动态交互的阶段。这些服务器端的动态页面技术是的网页可以获取服务器的数据信息并保持更新，推动了以 Google 为代表的搜索引擎和各种论坛的出现，Web 开始快速发展。服务器端网页动态交互功能不断丰富，伴随的是后端逻辑复杂度的快速上升以及及代码越来越复杂。为了更好地管理后端逻辑，出现了大量后端的 MVC 框架。</p><p>动态页面实现了动态交互和数据即时存和取，当由于动态页面是由后端技术驱动的，每一次的数据交互都需要刷新一次浏览器，频繁的页面刷新非常影响用户的体验，这个问题直到Goole公司在2004年使用Ajax技术开发的Gmail和GoogleMaps的发布后才得到解决。</p><h2 id="Ajax">Ajax</h2><p>Ajax改变了传统的用户请求——等待——响应这种web的交互模式，采用异步交互机制避免了用户对服务器响应的等待。提供了更好的用户体验，此外，它还改变了用户请求—服务器响应—-页面刷新的用户体验方式，提供了页面局部刷新数的实现机制，Ajax开启了Web2.0时代。</p><p>由于Ajax的火热，也带动了一些古老技术的复兴，css和javascript这两个原先被程序员瞧不上的技术收到了前所未有的关注，而这一切都源于Ajax带来的全新的用户体验。</p><blockquote><p>Ajax全称是：<strong>Asynchronous Javascript And Xml</strong> 即异步<strong>Javascript</strong>和<strong>XML</strong>。<br>Ajax最早是由Adaptive Path公司的咨询顾问Jese James Garrett于2005年提出的。Garrett专门写了一篇文章来讲述Ajax这一新的Web开发方式。Ajax为用户带来了更好的用户体验，在传统的web应用程序中，用户向服务器发送一个请求，然后等待，服务器对应请求进行处理，然后返回一个响应，这是一种同步的处理方式，如果服务器处理请求的时间比较长，那么用户将不得不长时间的等待。在后台执行程序的过程中，如果执行的程序出现异常还可能导致某个业务的执行出错会影响整个的体验。</p></blockquote><h3 id="同步请求和异步请求的利弊，为什么同步请求不总是可行">同步请求和异步请求的利弊，为什么同步请求不总是可行</h3><p>传统的页面应用中，当一个请求进来，服务器开始进行动态渲染，把数据作用域放到数据模型中，然后再跳转到视图层，然后在用户端页面上用诸如JSP等语法替换，来实现动态化 。动态化的覆盖本质上就是将查询到的数据使用动态语言来实现渲染，但是这种情况很消耗服务器资源流量。网页访问的总时长就是所有方法调用的单个时长的汇总，如果说在方法执行的过程中有一个数据的查询消耗了过多的服务器资源和时间，由于JAVA语法的执行时串行执行，在这个方法调用之后的所有方法都需要等待这个方法调用完毕之后再去执行，这个时间过长势必会影响用户体验；此外，如果在方法执行过程用有一个报错，那么服务器直接抛出异常，跳转错误页面。</p><p>而Ajax可以提前先把页面的html，css渲染出来，等页面加载完毕之后，再用事件的方式到服务器端偷偷请求，再把数据请求回来加载在页面上。这就是异步思想就不会出现因为某一个报错或者消耗时间过长来影响我的加载速度或者页面渲染。异步请求本质上是一种局部刷新。如果存在后一个方法接口没有加载出来也仅仅是会影响当前区域的加载，不糊影响到整体布局。</p><img src="/2022/02/22/Vue3%E8%83%8C%E6%99%AF%E8%AE%A4%E8%AF%86%E5%92%8C%E9%9D%A2%E8%AF%95%E7%82%B9/1.png" class=""><p>req和resp只会从服务器请求出来页面的基本样式（html，css），而数据则是通过Ajax异步的方式去偷偷请求，这样会在最大程度上提高服务器的吞吐量，而且每一个线程间互不影响。</p><h3 id="为什么ajax服务器端早期返回的是xml，现在是json呢？">为什么ajax服务器端早期返回的是xml，现在是json呢？</h3><p>不论我们通过ajax还是正常的请求/响应，其目的都是为了获取服务器的数据，渲染页面。</p><p>正常的请求和响应，每种语音都有在服务器端渲染的方式，比如：jsp + 标签/el表达式。这是一种服务器端渲染方式。都是一种语言，都是自家人，解析认识的。</p><p>异步请求服务端：服务端给予客户端什么样数据格式就是命题了？———-javascript——jsp/php/asp（例子：把一个java对象返还给js，肯定不会被识别）</p><p>如果用字符串自己拼接返回，可能会你分隔符会和具体内容冲突就不适合，例如“#，*”等比较常见的分隔符号，如果说系统或者用户数据中存在同类型的特殊字符，则会影响到数据分割。</p><p>所以早期的ajax异步处理是通过xml字符串进行传输，然后js有domxml对象可以对xml进行解析获取每个点的值，然后进行渲染。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line">user.setId(<span class="number">1</span>);</span><br><span class="line">user.setName(<span class="string">&quot;yykk&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;&lt;id&gt;1&lt;/id&gt;&lt;name&gt;yykk&lt;/name&gt;&quot;</span>;  <span class="comment">//js--domxml</span></span><br></pre></td></tr></table></figure><p>进几年来，后面xml笔记的笨重。节点过多，层级过深，解析也一个很大的问题，所以新的数据格式应运而生：json。</p><p>从这里要明白一个道理：xml也好还是json也好，都是一种有格式的<strong>字符串</strong>，方便你解析和获取，仅此而已。浏览器和服务器的数据交互方式永远是字符串形式。</p><h1>MVC，MVP 和 MVVM</h1><h2 id="MVC">MVC</h2><p><strong>MVC</strong>是从Web开发中应用非常广泛的一种框架模式，之后又演变出了MVP模式和MVVM模式。</p><p>在 MVC 模式中，一个应用被分成三个部分，即模型（Model)、视图（View）和控制器(Controller)。</p><blockquote><p><strong>什么是MVC？</strong><br>MVC（Model-View-Controller）即模型-视图-控制层，MVC框架有助于将应用程序分割成若干逻辑部件，使程序设计变得更加容易。MVC框架提供了一种按功能对各种对象进行分割的方法，其目的：将各对象间的耦合程度降到最低，</p></blockquote><p><strong>模型</strong>：代表应用程序的数据以及用于访问控制和修改这些数据的业务规则。当模型发生改变时，它会通知视图，并为视图提供查询模型相关状态的能力。同时，它也为控制器提供访问封装在模型内部的应用程序功能的能力。</p><p><strong>视图</strong>：用来组织模型的内容。它从模型获得数据并指定这些数据如何表现。当模型变化时，视图负责维护数据表现的一致性。视图同时将用户的请求通知控制器。</p><p><strong>控制器</strong>：定义了应用程序的行为。它负责对来自视图的用户请求进行解释，并把这些请求映射成相应的行为，这些行为由模型负责实现。在独立运行的 GUI客户端，用户的请求可能是一些鼠标单击或菜单选择操作。在一个 Web 应用程序中，它们的表现形式可能是一些来自客户端的 GET 或 POST 的 HTTP 请求。模型所实现的行为包括处理业务和修改模型的状态。根据用户请求和模型行为的结果，控制器选择一个视图作为对用户请求的响应。图 1-1描述了 MVC 模式中模型、视图、</p><p><strong>控制器三部分的关系</strong></p><img src="/2022/02/22/Vue3%E8%83%8C%E6%99%AF%E8%AE%A4%E8%AF%86%E5%92%8C%E9%9D%A2%E8%AF%95%E7%82%B9/2.png" class=""><p>而接下来提到的MVP和MVVM模式，都是由MVC模式演化而来，把数据和模版的渲染从后端转移到前端，从而实现减轻服务器压力的一种模式。</p><h2 id="MVP">MVP</h2><p>MVP（Model-View-Presenter）是由经典的 MVC 模式演变而来，它们的基本思想有相通的地方：模型（Model）提供数据，视图（View）负责显示，表示器（Presenter）负责逻辑的处理。<br>MVP 与 MVC 最大的区别是：在 MVP 中 View 并不直接使用 Model，它们之间的通信是通过Presenter 进行的，所有的交互都发生在 Presenter 内部，而在 MVC 中 View 会直接从 Model 中读取数据而不是通过 Controller。</p><p>MVP 模式中模型、视图和表示器三者的关系如图所示。</p><img src="/2022/02/22/Vue3%E8%83%8C%E6%99%AF%E8%AE%A4%E8%AF%86%E5%92%8C%E9%9D%A2%E8%AF%95%E7%82%B9/3.png" class=""><h2 id="MVVM">MVVM</h2><p>MVVM（Model-View-ViewModel）是一种软件框架模式（由微软公司的 WPF 和 Sivetighn的架构师 Ken Cooper 和 Ted Peters 开发)，也是一种简化用户界面的事件驱动编程方式，由 JohmGossman（微软公司的 WPF 和 Silverlight 的另一架构师）于 2005 年在他的博客上发表。</p><p>MVVM模式的核心是数据驱动，即 ViewModel，ViewModel是 View和Moiel 的关系映射。ViewModel 是一个值转换器（Value Converer），负责转换 Model中的数据对象，使数据变得更加易于管理和使用。在 MVVM 中 View 和Model是不可以直接进行通信的，它们之间存在着ViewModel 这个中介，充当观察者的角色。</p><p>MVVM模式最核心的特征就是 <strong>双向数据绑定</strong>，当用户操作 View时，ViewModel 感知到变化，然后通知Model发生了相应改变。反之，Model发生了改变，ViewModel感知到变化，然后通知View进行更新。ViewModel向上与View进行双向数据绑定，向下与Model通过接口请求进行数据交互，起到承上启下的作用：</p><img src="/2022/02/22/Vue3%E8%83%8C%E6%99%AF%E8%AE%A4%E8%AF%86%E5%92%8C%E9%9D%A2%E8%AF%95%E7%82%B9/4.png" class=""><p>MVVM的核心理念是：通过声明书的数据绑定实现View的分离，完成解耦View。</p><p>最具有代表性的前端框架有：Angular、Vue。</p><h1>初识 Vue.js</h1><p>Vue是一套基于MVVM模式的用于构建用户界面的Javascript框架。它是以数据驱动和组件化的思想构建的。Vuej是由一个名叫尤雨溪的作者开发的，他于 2013 年12月7 日发布了 Vuejs 的 0.6.0版本（之前的版本不叫 Vue.js），2015年10月26 日发布了 1.0.0 版本，2016 年 10 月1日发布了 2.0.0 版本，2020年 9 月 18日发布了3.0版本代号为 One Pieee。本书内容基于最新发布的 Vue.js 3.0 版本。</p><h2 id="渐进式框架">渐进式框架</h2><p>Vue 是渐进式的 JavaSeript 框架。所谓渐进式，就是把框架进行分层设计，每层都是可选的。框架的选择取决于你所设计的系统的架构大小。</p><p>最核心的是：声明式渲染，向外是组件系统，在这个基础上再加入前端理由和状态挂你，最外层的构建系统。</p><p>从内到外：声明式渲染，组件系统，前端路由（vue-router），状态管理（vuex），构建系统（vue-cli）</p><ol><li><p>假如你的系统比较简单，更多的是需要访问界面中的DOM节点，以获取用户输入数据或将更新后的数据渲染到视图中，那么可以将Vuejs作用一个javascript库来使用。使用他的声明式渲染机制可以轻松地操作DOM。实现数据变化时的自动视图渲染。</p></li><li><p>如果你前端界面比较复杂，那么可以考虑将界面元素组件化，利用Vuejs的组件化系统将界面元素与业务逻辑包装在为一个个组件。采用分而治之的的策略。不但可以降低前端系统的复杂度，组件本身还可以复用。</p></li><li><p>如果要求将前后端分离，将前端做成单页应用程序，那么可以引入前端理由Vue Router，实现单页应用，如果前端应用中有很多需要在多个组件间共享，如果用户数据，那么可以引入Vuex统一对状态进行管理。</p></li><li><p>Vue提供的构建系统可以轻松地搭建一个脚手架项目，项目内置了运行环境，便于开发，调试并观察程序的运行结果，此外项目也集成了Webpack打包工具。可以很容易地构建发布。</p></li></ol><h2 id="Vue初始化的规律">Vue初始化的规律</h2><ul><li>初始化是固定格式，Vue.createApp任何一个单词都不能写错，必须完全匹配</li><li>vue3和vue3的改变，初始化发生了改变，data不再是一个对象，而是一个函数+返回对象+生命周期，三者进行融合</li><li>如果页面上的数据需要被替换，那么就必须先到data中定义一个属性</li><li>想尽一切办法然后通过axios或者一些事件去改变这个data的属性，vue就会自动替换view视图</li><li>再替换过程中，可能会用到vue指令和语法</li></ul>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
            <tag> Vue </tag>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Intro to AI Chapter 3 Uncertainty</title>
      <link href="/2022/02/20/Intro-to-AI-Chapter-3-Uncertainty/"/>
      <url>/2022/02/20/Intro-to-AI-Chapter-3-Uncertainty/</url>
      
        <content type="html"><![CDATA[<h1>Chapter 3 Uncertainty</h1><h2 id="Probability">Probability</h2><p>Uncertainty can be represented as a number of events and the likelihood, or probability, of each of them happening.</p><h3 id="Axioms-in-Probability">Axioms in Probability</h3><ul><li>0 &lt; $P(ω)$ &lt; 1: every value representing probability must range between 0 and 1.<ul><li>Zero is an impossible event, like rolling a standard die and getting a 7.</li><li>One is an event that is certain to happen, like rolling a standard die and getting a value less than 10.</li><li>In general, the higher the value, the more likely the event is to happen.</li></ul></li><li>The probabilities of every possible event, when summed together, are equal to 1.</li></ul><p>$$<br>\sum_{\omega \in \Omega} P(\omega) = 1<br>$$</p><p>To get the probability of an event, we divide the number of worlds in which it occurs by the number of total possible worlds. For example, there are 36 possible worlds when rolling two dice. Only in one of these worlds, when both dice yield a 6, do we get the sum of 12. Thus, $P(12) = 1/36$, or, in words, the probability of rolling two dice and getting two numbers whose sum is 12 is 1/36. What is $P(7)$? We count and see that the sum 7 occurs in 6 worlds. Thus, $P(7) = 6/36 = 1/6$.</p><h3 id="Unconditional-Probability">Unconditional Probability</h3><p>Unconditional probability is the degree of belief in a proposition in the absence of any other evidence. All the questions that we have asked so far were questions of unconditional probability, because the result of rolling a die is not dependent on previous events.</p><h2 id="Conditional-Probability">Conditional Probability</h2><p>Conditional probability is the degree of belief in a proposition given some evidence that has already been revealed. As discussed in the introduction, AI can use partial information to make educated guesses about the future. To use this information, which affects the probability that the event occurs in the future, we rely on conditional probability.</p><p>Conditional probability is expressed using the following notation: $P(a \mid b)$, meaning “the probability of event a occurring given that we know event b to have occurred,” or, more succinctly, “the probability of a given b.” Now we can ask questions like what is the probability of rain today given that it rained yesterday $P(rain today \mid rain yesterday)$, or what is the probability of the patient having the disease given their test results $P(disease \mid test results)$.</p><p>Mathematically, to compute the conditional probability of a given b, we use the following formula:</p><p>$$P(a \mid b) = \frac{P(a \wedge b)}{P(b)}$$</p><p>To put it in words, the probability that a given b is true is equal to the probability of a and b being true, divided by the probability of b. An intuitive way of reasoning about this is the thought “we are interested in the events where both a and b are true (the numerator), but only from the worlds where we know b to be true (the denominator).” Dividing by b restricts the possible worlds to the ones where b is true. The following are algebraically equivalent forms to the formula above:</p><p>$$P(a \wedge b) = P(b)P(a \mid b)$$</p><p>$$P(a \wedge b) = P(a)P(b \mid a)$$</p><h2 id="Random-Varibles">Random Varibles</h2><p>A random variable is a variable in probability theory with a domain of possible values that it can take on. For example, to represent possible outcomes when rolling a die, we can define a random variable Roll, that can take on the values {0, 1, 2, 3, 4, 5, 6}. To represent the status of a flight, we can define a variable Flight that takes on the values {on time, delayed, canceled}.</p><p>Often, we are interested in the probability with which each value occurs. We represent this using a probability distribution. For example,</p><ul><li>$P(Flight = on time) = 0.6$</li><li>$P(Flight = delayed) = 0.3$</li><li>$P(Flight = canceled) = 0.1$<br>To interpret the probability distribution with words, this means that there is a 60% chance that the flight is on time, 30% chance that it is delayed, and 10% chance that it is canceled. Note that, as shown previously, the sum the probabilities of all possible outcomes is 1.</li></ul><p>A probability distribution can be represented more succinctly as a vector. For example, $P(Flight) = &lt;0.6, 0.3, 0.1&gt;$. For this notation to be interpretable, the values have a set order (in our case, on time, delayed, canceled).</p><h3 id="Independence">Independence</h3><p>Independence is the knowledge that the occurrence of one event does not affect the probability of the other event. For example, when rolling two dice, the result of each die is independent from the other. Rolling a 4 with the first die does not influence the value of the second die that we roll. This is opposed to dependent events, like clouds in the morning and rain in the afternoon. If it is cloudy in the morning, it is more likely that it will rain in the morning, so these events are dependent.</p><p>Independence can be defined mathematically: events a and b are independent if and only if the probability of a and b is equal to the probability of a times the probability of b: $P(a \wedge b) = P(a)P(b)$.</p><h2 id="Bayes’-Rule">Bayes’ Rule</h2><p>Bayes’ rule is commonly used in probability theory to compute conditional probability. In words, Bayes’ rule says that the probability of b given a is equal to the probability of a given b, times the probability of b, divided by the probability of a.</p><p>$$<br>P(b \mid a) = \frac{P(b)P(a \mid b)}{P(a)}$$</p><p>Knowing $P(a \mid b)$, in addition to $P(a)$ and $P(b)$, allows us to calculate $P(b \mid a)$. This is helpful, because knowing the conditional probability of a visible effect given an unknown cause, P(visible effect | unknown cause), allows us to calculate the probability of the unknown cause given the visible effect, P(unknown cause | visible effect). For example, we can learn P(medical test results | disease) through medical trials, where we test people with the disease and see how often the test picks up on that. Knowing this, we can calculate P(disease | medical test results), which is valuable diagnostic information.</p><h2 id="Joint-Probability">Joint Probability</h2><p>Joint probability is the likelihood of multiple events all occurring.</p><p>We need to look at the joint probabilities of all the possible outcones of thhe 2 varibles.</p><table><thead><tr><th>C = cloud</th><th>C = $\neg$ cloud</th></tr></thead><tbody><tr><td>0.4</td><td>0.6</td></tr></tbody></table><table><thead><tr><th>R = rain</th><th>R = $\neg$ rain</th></tr></thead><tbody><tr><td>0.1</td><td>0.9</td></tr></tbody></table><table><thead><tr><th></th><th>R = rain</th><th>R = $\neg$ rain</th></tr></thead><tbody><tr><td><strong>C</strong> = cloud</td><td>0.08</td><td>0.32</td></tr><tr><td><strong>C</strong> = $\neg$ cloud</td><td>0.02</td><td>0.58</td></tr></tbody></table><blockquote><p>In fact, the joint probability here is not the result of calculation, but a rule of thought.</p></blockquote><p>Now we are able to know information about the co-occurrence of the events. For example, we know that the probability of a certain day having clouds in the morning and rain in the afternoon is 0.08. The probability of no clouds in the morning and no rain in the afternoon is 0.58.</p><p>Using joint probabilities, we can deduce conditional probability. For example, if we are interested in the probability distribution of clouds in the morning given rain in the afternoon. $P(C \mid rain) = \frac{P(C, rain)}{P(rain)}$ (a side note: in probability, commas and $\wedge$ are used interchangeably. Thus, $P(C, rain) = P(C \wedge rain))$. In words, we divide the joint probability of rain and clouds by the probability of rain.</p><p>In the last equation, it is possible to view $P(rain)$ as some constant by which $P(C, rain)$ is multiplied. Thus, we can rewrite $\frac{P(C, rain)}{P(rain)} = \alpha P(C, rain)$, or $\alpha &lt;0.08, 0.02&gt;$. Factoring out α leaves us with the proportions of the probabilities of the possible values of C given that there is rain in the afternoon. Namely, if there is rain in the afternoon, the proportion of the probabilities of clouds in the morning and no clouds in the morning is 0.08:0.02. Note that 0.08 and 0.02 don’t sum up to 1; however, since this is the probability distribution for the random variable C, we know that they should sum up to 1. Therefore, we need to normalize the values by computing α such that $\alpha 0.08 + \alpha 0.02 = 1$. Finally, we can say that $P(C \mid rain) = &lt;0.8, 0.2&gt;$.</p><p>因为这中间需要包涵到cloud的两种情况，即晴天或者多云，两种情况的概率总和为1,没有第三种可能的情况，所以两种情况的等比扩大和应为1（也可以理解为矩阵加法），由此我们可以推导出对应特定条件的单一条件的概率。</p><h2 id="Probability-Rules">Probability Rules</h2><p>Negation: $P(\neg a) = 1 - P(a)$. This stems from the fact that the sum of the probabilities of all the possible worlds is 1, and the complementary literals $a$ and $\neg a$ include all the possible worlds.</p><p>Inclusion-Exclusion: $P(a \vee b) = P(a) + P(b) - P(a \wedge b)$. This can interpreted in the following way: the worlds in which a or b are true are equal to all the worlds where a is true, plus the worlds where b is true. However, in this case, some worlds are counted twice (the worlds where both a and b are true)). To get rid of this overlap, we subtract once the worlds where both a and b are true (since they were counted twice).</p><p>Here is an example from outside lecture that can elucidate this. Suppose I eat ice cream 80% of days and cookies 70% of days. If we’re calculating the probability that today I eat ice cream or cookies $P(ice cream \vee cookies)$ without subtracting $P(ice cream \wedge cookies)$, we erroneously end up with 0.7 + 0.8 = 1.5. This contradicts the axiom that probability ranges between 0 and 1. To correct for counting twice the days when I ate both ice cream and cookies, we need to subtract $P(ice cream \wedge cookies)$ once.</p><h3 id="Marginalization">Marginalization</h3><p>$P(a) = P(a, b) + P(a, \neg b)$. The idea here is that $b$ and $\neg b$ are disjoint probabilities. That is, the probability of $b$ and $\neg b$ occurring at the same time is 0. We also know $b$ and $\neg b$ sum up to 1. Thus, when a happens, $b$ can either happen or not. When we take the probability of both a and b happening in addition to the probability of $a$ and $\neg b$, we end up with simply the probability of a.</p><p>Marginalization can be expressed for random variables the following way:</p><p>$$P(X = x_{i}) = \sum_{j}P(X = x_{i}, Y = y_{i})$$</p><p>The left side of the equation means “The probability of random variable X having the value $x_{i}$.” For example, for the variable C we mentioned earlier, the two possible values are clouds in the morning and no clouds in the morning. The right part of the equation is the idea of marginalization. $P(X = x_{i})$ is equal to the sum of all the joint probabilities of $x_{i}$ and every single value of the random variable Y.</p><h3 id="Conditioning">Conditioning</h3><p>$P(a) = P(a \mid b)P(b) + P(a \mid \neg b)P(\neg b)$. This is $a$ similar idea to marginalization. The probability of event $a$ occurring is equal to the probability of a given $b$ times the probability of $b$, plus the probability of a given $\neg b$ time the probability of $\neg b$.</p><p>$$P(X = x_{i}) = \sum_{j}P(X = x_{i} \mid Y = y_{i})P(Y = y_{i})$$</p><p>In this formula, the random variable X takes the value $x_{i}$ with probability that is equal to the sum of the probabilities of $x_{i}$ given each value of the random variable Y multiplied by the probability of variable Y taking that value. This makes sense if we remember that $P(a \mid b) = \frac{P(a, b)}{P(b)}$. If we multiply this expression by $P(b)$, we end up with $P(a, b)$, and from here we do the same as we did with marginalization.</p><h2 id="Beyesian-Networks">Beyesian Networks</h2><p>A Bayesian network is a data structure that represents the dependencies among random variables. Bayesian networks have the following properties:</p><p>They are directed graphs.</p><ul><li>Each node on the graph represent a random variable.</li><li>An arrow from X to Y represents that X is a parent of Y. That is, the probability distribution of Y depends on the value of X.</li><li>Each node X has probability distribution $P(X \mid Parents(X))$.</li></ul><p>In other words, if we want to find the probability of events under specific conditions, in a complex Bayesian network, we only need to consider the previous conditions of the current situation and go back to the initial conditions. The conditional probability under the current conditions can be used as the result of the preconditions and go back to the initial conclusion.</p><p>We make A hypothesis that if A is the most initial condition, A indicates B, A also indicates C, B indicates C, and C indicates D. each condition contains three seeds. If we want to find the probability of a specific case in condition D under three different specific conditions of A, B, C. As shown in the following table:</p><table><thead><tr><th>A</th><th></th><th></th></tr></thead><tbody><tr><td>$\downarrow$</td><td>$\searrow$</td><td></td></tr><tr><td><strong>B</strong></td><td>$\to$</td><td><strong>C</strong></td></tr><tr><td></td><td></td><td>$\downarrow$</td></tr><tr><td></td><td></td><td><strong>D</strong></td></tr></tbody></table><p>And we assume that each of the condtions contains 3 sub cases $\alpha , \beta  and  \gamma$.</p><p>So now, if we want to calculate the probability of $\alpha$ in condition D, when C is in $\beta$, B is in $\gamma$ and A is also in $\gamma$. We need to combine all the circumstances to compute. As the answer follows:</p><p>$$P（A_{\gamma}, B_{\gamma}, C_{\beta}, D_{\alpha}） = P(D_{\alpha} \mid C_{\beta})P(C_{\beta} \mid A_{\gamma}, B_{\gamma})P(B_{\gamma} \mid A_{\gamma})P(A_{\gamma})$$</p><h3 id="Inference">Inference</h3><p>We could definitively conclude new information based on the information that we already had. We can also infer new information based on probabilities. While this does not allow us to know new information for certain, it allows us to figure out the probability distributions for some values. Inference has multiple properties.</p><ul><li>Query <strong>X</strong>: the variable for which we want to compute the probability distribution.</li><li>Evidence variables <strong>E</strong>: one or more variables that have been observed for event e. For example, we might have observed that there is light rain, and this observation helps us compute the probability that the train is delayed.</li><li>Hidden variables <strong>Y</strong>: variables that aren’t the query and also haven’t been observed. For example, standing at the train station, we can observe whether there is rain, but we can’t know if there is maintenance on the track further down the road. Thus, Maintenance would be a hidden variable in this situation.</li><li>The <strong>goal</strong>: calculate $P(X \mid e)$. For example, compute the probability distribution of the Train variable (the query) based on the evidence e that we know there is light rain.</li></ul><h3 id="Inference-by-Enumeration">Inference by Enumeration</h3><p>Inference by enumeration is a process of finding the probability distribution of variable X given observed evidence e and some hidden variables Y.</p><p>$$P(X \mid e) = \alpha P(X, e) = \alpha \sum_{y} P(X, e, y)$$</p><p>In this equation, $X$ stand for the query variable, $e $for the observed evidence, $y$ for all the values of the hidden variables, and $\alpha$ normalizes the result such that we end up with probabilities that add up to 1. To explain the equation in words, it is saying that the probability distribution of $X$ given $e$ is equal to a normalized probability distribution of $X$ and $e$. To get to this distribution, we sum the normalized probability of $X$, $e$, and $y$, where $y$ takes each time a different value of the hidden variables $Y$.</p><h2 id="Sampling">Sampling</h2><p>Sampling is one technique of approximate inference. In sampling, each variable is sampled for a value according to its probability distribution. We will start with an example from outside lecture, and then cover the example from lecture.</p><p>Because in most cases, we don’t need to predict very accurate things, just know the probability estimation of things, which will avoid a lot of complex and cumbersome calculations. The core view of Bayes is that it is different from observing the distribution of samples under specific parameters, but to make the samples full of randomness and analyze the distribution of parameters, that is, the samples are fixed, but the parameter attributes of each sample are random.</p><h3 id="Likelihood-Weighting-似然加权">Likelihood Weighting 似然加权</h3><ul><li>Start by fixing the values for evidence variables.</li><li>Sample the non-evidence variables using conditional probabilities in the Bayesian network.</li><li>Weight each sample by its likelihood: the probability of all the evidence occurring.</li></ul><p>For example, if we have the observation that the train was on time, we will start sampling as before. We sample a value of Rain given its probability distribution, then Maintenance, but when we get to Train - we always give it the observed value, in our case, on time. Then we proceed and sample Appointment based on its probability distribution given $Train = on time$. Now that this sample exists, we weight it by the conditional probability of the observed variable given its sampled parents. That is, if we sampled Rain and got light, and then we sampled Maintenance and got yes, then we will weight this sample by $P(Train = on time \mid light, yes)$.</p><h2 id="Markov-Models">Markov Models</h2><p>So far, we have looked at questions of probability given some information that we observed. In this kind of paradigm, the dimension of time is not represented in any way. However, many tasks do rely on the dimension of time, such as prediction. To represent the variable of time we will create a new variable, $X$, and change it based on the event of interest, such that $X_{t}$ is the current event, $X_{t+1}$ is the next event, and so on. To be able to predict events in the future, we will use Markov Models.</p><h3 id="The-Markov-Assumption">The Markov Assumption</h3><ul><li>将随机变量作为结点，若两个随机变量相关或者不独立，则将二者连接一条边；若给定若干随机变量，则形成一个有向图，即构成一个网络。</li><li>如果该网络是有向无环图，则这个网络称为贝叶斯网络。</li><li>如果这个图退化成线性链的方式，则得到马尔可夫模型；因为每个结点都是随机变量，将其看成各个时刻(或空间)的相关变化，以随机过程的视角，则可以看成是马尔可夫过程。</li><li>若上述网络是无向的，则是无向图模型，又称马尔可夫随机场或者马尔可夫网络。</li><li>如果在给定某些条件的前提下，研究这个马尔可夫随机场，则得到条件随机场。</li><li>如果使用条件随机场解决标注问题，并且进一步将条件随机场中的网络拓扑变成线性的，则得到线性链条件随机场。</li></ul><p>The Markov assumption is an assumption that the current state depends on only a finite fixed number of previous states. This is important to us. Think of the task of predicting weather. In theory, we could use all the data from the past year to predict tomorrow’s weather. However, it is infeasible, both because of the computational power this would require and because there is probably no information about the conditional probability of tomorrow’s weather based on the weather 365 days ago. Using the Markov assumption, we restrict our previous states (e.g. how many previous days we are going to consider when predicting tomorrow’s weather), thereby making the task manageable. This means that we might get a more rough approximation of the probabilities of interest, but this is often good enough for our needs. Moreover, we can use a Markov model based on the information of the one last event (e.g. predicting tomorrow’s weather based on today’s weather).</p><h3 id="Markov-Chain">Markov Chain</h3><p>A Markov chain is a sequence of random variables where the distribution of each variable follows the Markov assumption. That is, each event in the chain occurs based on the probability of the event before it.</p><p>To start constructing a Markov chain, we need a transition model that will specify the the probability distributions of the next event based on the possible values of the current event.</p><p>每个状态的转移只依赖于之前的n个状态，这个过程被称为1个n阶的模型，其中n是影响转移状态的数目。最简单的马尔可夫过程就是一阶过程，每一个状态的转移只依赖于其之前的那一个状态，这个也叫作马尔可夫性质。</p><p>$$P(X_{n+1} \mid X_{1} = x_{1}, X_{2} = x_{2},… , X_{n} = x_{n} = P(X_{n+1} = x \mid X_{n} = x_{n}))$$</p><h3 id="Hidden-Markov-Models">Hidden Markov Models</h3><p>A hidden Markov model is a type of a Markov model for a system with hidden states that generate some observed event. This means that sometimes, the AI has some measurement of the world but no access to the precise state of the world. In these cases, the state of the world is called the hidden state and whatever data the AI has access to are the observations. Here are a few examples for this:</p><p>For a robot exploring uncharted territory, the hidden state is its position, and the observation is the data recorded by the robot’s sensors.<br>In speech recognition, the hidden state is the words that were spoken, and the observation is the audio waveforms.</p><p>When measuring user engagement on websites, the hidden state is how engaged the user is, and the observation is the website or app analytics.</p><h3 id="Sensor-Markov-Assumption">Sensor Markov Assumption</h3><p>The assumption that the evidence variable depends only on the corresponding state. For example, for our models, we assume that whether people bring umbrellas to the office depends only on the weather. This is not necessarily reflective of the complete truth, because, for example, more conscientious, rain-averse people might take an umbrella with them everywhere even when it is sunny, and if we knew everyone’s personalities it would add more data to the model. However, the sensor Markov assumption ignores these data, assuming that only the hidden state affects the observation.</p><p>A hidden Markov model can be represented in a Markov chain with two layers. The top layer, variable X, stands for the hidden state. The bottom layer, variable E, stands for the evidence, the observations that we have.</p><p>Based on hidden Markov models, multiple tasks can be achieved:</p><ul><li><strong>Filtering</strong>: given observations from start until now, calculate the probability distribution for the current state. For example, given information on when people bring umbrellas form the start of time until today, we generate a probability distribution for whether it is raining today or not.</li><li><strong>Prediction</strong>: given observations from start until now, calculate the probability distribution for a future state.</li><li><strong>Smoothing</strong>: given observations from start until now, calculate the probability distribution for a past state. For example, calculating the probability of rain yesterday given that people brought umbrellas today.</li><li><strong>Most likely explanation</strong>: given observations from start until now, calculate most likely sequence of events.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Artificial Intelligence </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Artificial Intelligence </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Intro to AI Chapter 2 Knowledge</title>
      <link href="/2022/02/19/Intro-to-AI-Chapter-2-Knowledge/"/>
      <url>/2022/02/19/Intro-to-AI-Chapter-2-Knowledge/</url>
      
        <content type="html"><![CDATA[<h1>Chapter 2 Knowledge</h1><ul><li>knowledge-based agents<br>Agents that reason by operating on internal representations of knowledge. Somehow inside the AI, they have some understanding of what it means to know something.</li></ul><h2 id="Terms-and-Symbols">Terms and Symbols</h2><ul><li><p>sentence<br>An assertion about the world in a knowledge representation language.</p></li><li><p>propositional logic<br>Statement based on a logic of proposition, or just statements about the owrld.</p><ul><li><p>Proposition Symbol<br>P Q R, each of them represents a statement.</p></li><li><p>Logical Connectives<br>$\neg$ not  $\wedge$ and $\vee$ or $\rightarrow$ implication $\leftrightarrow$ biconditional</p></li></ul></li><li><p>knowledge base<br>A set of sentences known by a knowledge-based agent.</p></li><li><p>Entailment<br>In every model in which sentence $\alpha$ is true, sentence $\beta$ is also true.</p></li></ul><p>$$\alpha \models \beta$$</p><ul><li>inference<br>The process of driving new sentences from old ones.</li></ul><h2 id="Inference-Algorithm">Inference Algorithm</h2><h3 id="Model-checking">Model checking</h3><ul><li>To determine if <em>KB</em> $\models \alpha$<ul><li>Enumertate all possible models</li><li>If in every model where <em>KB</em> is true, $\alpha$ is true, then <em>KB</em> entails $\alpha$<br>(check whether KB is true first, and then check whether the Query is true under the circunstance that KB is true)</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">model_check</span>(<span class="params">knowledge, query</span>):</span><br><span class="line">    <span class="comment"># Checks if knowledge base entails query</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">check_all</span>(<span class="params">knowledge, query, symbols, model</span>):</span><br><span class="line">        <span class="comment"># If model has an assignment for each symbol</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> symbols:</span><br><span class="line">            <span class="comment"># If knowledge base is true in model, then the query must be true.</span></span><br><span class="line">            <span class="keyword">if</span> knowledge.evaluate(model):</span><br><span class="line">                <span class="keyword">return</span> query.evaluate(model)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Choose one of the unused remaining symbol.</span></span><br><span class="line">            remaining = symbols.copy()</span><br><span class="line">            p = remaining.pop()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Creat a model where symbol is true.</span></span><br><span class="line">            model_true = model.copy()</span><br><span class="line">            model_true[p] = <span class="literal">True</span></span><br><span class="line">            <span class="comment"># Creat a model where symbol is true.</span></span><br><span class="line">            model_false = model.copy()</span><br><span class="line">            model_false[p] = <span class="literal">False</span></span><br><span class="line">            <span class="comment"># Ensure entailment holds both circumstances</span></span><br><span class="line">            <span class="keyword">return</span>(check_all(knowledge, query, remaining, model_true) <span class="keyword">and</span> check_all(knowledge, query, remaining, model_false))</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Get all symbols in both knowledge and query</span></span><br><span class="line">    symbols = <span class="built_in">set</span>.union(knowledge.symbols(), query.symbols())</span><br><span class="line"></span><br><span class="line">    <span class="comment">#check that knowledge base entails query</span></span><br><span class="line">    <span class="keyword">return</span> check_all(knowledge, query, symbols, <span class="built_in">dict</span>())    </span><br></pre></td></tr></table></figure><h2 id="Knowledge-Engineering">Knowledge Engineering</h2><p>We can use a computer to be able to represent knowledge and draw conclusions based on that knowledge.<br>At anytime we can translate something into propositional logic symbols, type of aproach can be useful.</p><h2 id="Inference-Rules">Inference Rules</h2><p>Model Checking is not an efficient algorithm because it has to consider every possible model before giving the answer (a reminder: a query R is true if under all the models (truth assignments) where the KB is true, R is true as well). Inference rules allow us to generate new information based on existing knowledge without considering every possible model.</p><p>Inference rules are usually represented using a horizontal bar that separates the top part, the premise, from the bottom part, the conclusion. The premise is whatever knowledge we have, and the conclusion is what knowledge can be generated based on the premise.</p><p>In this example, our premise consists of the following propositions:</p><ul><li>If it is raining, then Harry is inside.</li><li>It is raining.</li></ul><p>Based on this, most reasonable humans can conclude that</p><ul><li>Harry is inside.</li></ul><h3 id="Modus-Ponens">Modus Ponens</h3><p>The type of inference rule we use in this example is Modus Ponens, which is a fancy way of saying that if we know an implication and its antecedent to be true, then the consequent is true as well.</p><p>$$\alpha \rightarrow \beta$$</p><p>$$\alpha$$</p><hr><p>$$\beta$$</p><p>This means if we have known the deduction that $\alpha$ implicates $\beta$, and also we have confirmed that $\alpha$ is true, so that we can also conclude that $\beta$ is true.</p><h3 id="And-Elimination">And Elimination</h3><p>If an And proposition is true, then any one atomic proposition within it is true as well.</p><p>$$\alpha \wedge \beta$$</p><hr><p>$$\alpha$$</p><h3 id="Double-Negation-Elimination">Double Negation Elimination</h3><p>A proposition that is negated twice is true. For example, consider the proposition “It is not true that Harry did not pass the test”. We can parse it the following way: “It is not true that (Harry did not pass the test)”, or “$\neg$(Harry did not pass the test)”, and, finally “$\neg$($\neg$(Harry passed the test)).” The two negations cancel each other, marking the proposition “Harry passed the test” as true.</p><p>$$(\neg(\neg \alpha))$$</p><hr><p>$$\alpha$$</p><h3 id="Implication-Elimination">Implication Elimination</h3><p>An implication is equivalent to an Or relation between the negated antecedent and the consequent. As an example, the proposition “If it is raining, Harry is inside” is equivalent to the proposition “(it is not raining) or (Harry is inside).”</p><p>$$\alpha \rightarrow \beta$$</p><hr><p>$$\neg \alpha \vee \beta$$</p><h3 id="Biconditional-Elimination">Biconditional Elimination</h3><p>A biconditional proposition is equivalent to an implication and its inverse with an And connective.</p><p>$$\alpha \Leftrightarrow \beta$$</p><hr><p>$$(\alpha \rightarrow \beta) \wedge (\beta \rightarrow \alpha)$$</p><h3 id="De-Morgan’s-Law">De Morgan’s Law</h3><p>It is possible to turn an And connective into an Or connective. That is, for the And proposition earlier to be true, at least one of the propositions in the Or propositions must be true. Similarly, it is possible to conclude the reverse.</p><p>$$\neg(\alpha \wedge \beta)$$</p><hr><p>$$\neg \alpha \vee \neg \beta$$</p><p>$$\neg(\alpha \vee \beta)$$</p><hr><p>$$\neg \alpha \wedge \neg \beta$$</p><h3 id="Distributive-Property">Distributive Property</h3><p>A proposition with two elements that are grouped with And or Or connectives can be distributed, or broken down into, smaller units consisting of And and Or.</p><p>$$(\alpha \wedge(\beta \vee \gamma))$$</p><hr><p>$$(\alpha \wedge \beta)\vee(\alpha \wedge \beta)$$</p><h2 id="Theorem-Proving">Theorem Proving</h2><ul><li>Initial state: starting knowledge base</li><li>Actions: inference rules</li><li>Transition model: new knowledge base after inference</li><li>Goal test: checking whether the statement that we are trying to prove is in the KB</li><li>Path cost function: the number of steps in the proof</li></ul><h2 id="Resolution">Resolution</h2><p>Resolution is a powerful inference rule that states that if one of two atomic propositions in an Or proposition is false, the other has to be true. More formally, we can define resolution the following way:</p><p>$$P \vee Q$$<br>$$\neg P$$</p><hr><p>$$Q$$</p><p>Resolution relies on Complementary Literals, two of the same atomic propositions where one is negated and the other is not, such as P and $\neg$ P.</p><p>Complementary literals allow us to generate new sentences through inferences by resolution. Thus, inference algorithms locate complementary literals to generate new knowledge.</p><h2 id="Clause">Clause</h2><p>A <strong>Clause</strong> is a disjunction of <strong>literals</strong> (a propositional symbol or a negation of a propositional symbol, such as P, $\neg$  P). A disjunction consists of propositions that are connected with an Or logical connective (P $\vee$ Q $\vee$ R). A <strong>conjunction</strong>, on the other hand, consists of propositions that are connected with an <strong>And</strong> logical connective (P $\wedge$ Q $\wedge$ R). Clauses allow us to convert any logical statement into a <strong>Conjunctive Normal Form</strong> (CNF), which is a conjunction of clauses, for example: (A $\vee$ B $\vee$ C) $\wedge$ (D $ \vee \neg$ E) $\wedge$ (F $\vee$ G).</p><h2 id="Steps-in-Conversion-of-Propositions-to-Conjunctive-Normal-Form">Steps in Conversion of Propositions to Conjunctive Normal Form</h2><ul><li>Eliminate biconditionals<ul><li>Turn ($\alpha \Leftrightarrow \beta$) into ($\alpha \rightarrow \beta$) $\wedge$ ($\beta \rightarrow \alpha$).</li></ul></li><li>Eliminate implications<ul><li>Turn ($\alpha \rightarrow \beta$) into $\neg \alpha \vee \beta$.</li></ul></li><li>Move negation inwards until only literals are being negated (and not clauses), using De Morgan’s Laws.<ul><li>Turn $\neg(\alpha \wedge \beta)$ into $\neg \alpha \vee \neg \beta$</li></ul></li></ul><p>Here’s an example of converting $(P \vee Q) \rightarrow R$ to Conjunctive Normal Form:</p><p>$(P \vee Q) \rightarrow R$<br>$\neg(P \vee Q) \vee R$  ==Eliminate implication==<br>$(\neg P \wedge \neg Q) \vee R$ ==De Morgan’s Law==<br>$(\neg P \vee R) \wedge (\neg Q \vee R)$ ==Distributive Law==<br>At this point, we can run an inference algorithm on the conjunctive normal form. Occasionally, through the process of inference by resolution, we might end up in cases where a clause contains the same literal twice. In these cases, a process called factoring is used, where the duplicate literal is removed. For example, $(P \vee Q \vee S) \wedge (\neg P \vee R \vee S)$ allow us to infer by resolution that $(Q \vee S \vee R \vee S)$. The duplicate $S$ can be removed to give us $(Q \vee R \vee S)$.</p><p>Resolving a literal and its negation, i.e. $\neg P$ and $P$, gives the <em>==empty clause()==</em>. The empty clause is always false, and this makes sense because it is impossible that both $P$ and $\neg P$ are true. This fact is used by the resolution algorithm.</p><ul><li>To determine if $KB \models \alpha$:<ul><li>Check: is $(KB \wedge \neg \alpha)$ a contradiction?</li><li>If so, then $KB \models \alpha$.</li><li>Otherwise, no entailment.</li></ul></li></ul><p>Proof by contradiction is a tool used often in computer science. If our knowledge base is true, and it contradicts $\neg \alpha$, it means that $\neg \alpha$ is false, and, therefore, $\alpha$ must be true. More technically, the algorithm would perform the following actions:</p><p>To determine if $KB \models \alpha$:</p><ul><li>Convert $(KB \wedge \neg \alpha)$ to Conjunctive Normal Form.</li><li>Keep checking to see if we can use resolution to produce a new clause.</li><li>If we ever produce the empty clause (equivalent to False), congratulations! We have arrived at a contradiction, thus proving that $KB \models \alpha$.</li><li>However, if contradiction is not achieved and no more clauses can be inferred, there is no entailment.</li></ul><blockquote><p><strong>Here is an example that illustrates how this algorithm might work:</strong><br>Does $(A \vee B) \wedge (\neg B \vee C) \wedge (\neg C)$ entail $A$?<br>First, to prove by contradiction, we assume that A is false. Thus, we arrive at $(A \vee B) \wedge (\neg B \vee C) \wedge (\neg C) \wedge (\neg A)$.<br>Now, we can start generating new information. Since we know that $C$ is false $(\neg C)$, the only way $(\neg B \vee C)$ can be true is if $B$ is false, too. Thus, we can add $(\neg B)$ to our $KB$.<br>Next, since we know $(\neg B)$, the only way $(A \vee B)$ can be true is if $A$ is true. Thus, we can add $(A)$ to our $KB$.<br>Now our KB has two complementary literals, $(A)$ and $(\neg A)$. We resolve them, arriving at the empty set, $()$. The empty set is false by definition, so we have arrived at a contradiction.</p></blockquote><h2 id="First-Order-Logic-一阶逻辑">First Order Logic 一阶逻辑</h2><p><strong>First order logic</strong> is another type of logic that allows us to express more complex ideas more succinctly than propositional logic. <strong>First order logic</strong> uses two types of symbols: Constant Symbols and Predicate Symbols. Constant symbols represent objects, while predicate symbols are like relations or functions that take an argument and return a true or false value.</p><p>For example, we return to the logic puzzle with different people and house assignments at Hogwarts. The constant symbols are people or houses, like Minerva, Pomona, Gryffindor, Hufflepuff, etc. The predicate symbols are properties that hold true or false of some constant symbols. For example, we can express the idea that Minerva is a person using the sentence $Person(Minerva)$. Similarly, we can express the idea the Gryffindor is a house using the sentence $House(Gryffindor)$. All the logical connectives work in first order logic the same way as before. For example, $\neg House(Minerva)$ expresses the idea that Minerva is not a house. A predicate symbol can also take two or more arguments and express a relation between them. For example, BelongsTo expresses a relation between two arguments, the person and the house to which the person belongs. Thus, the idea that Minerva belongs to Gryffindor can be expressed as $BelongsTo(Minerva, Gryffindor)$. First order logic allows having one symbol for each person and one symbol for each house. This is more succinct than propositional logic, where each person—house assignment would require a different symbol.</p><h3 id="Universal-Quantification">Universal Quantification</h3><p><strong>Quantification</strong> is a tool that can be used in first order logic to represent sentences without using a specific constant symbol. Universal quantification uses the symbol $\forall$  to express “for all.” So, for example, the sentence $\forall x. BelongsTo(x, Gryffindor) \rightarrow \neg BelongsTo(x, Hufflepuff) $ expresses the idea that it is true for every symbol that if this symbol belongs to Gryffindor, it does not belong to Hufflepuff.</p><h3 id="Existential-Quantification">Existential Quantification</h3><p><strong>Existential quantification</strong> is an idea parallel to universal quantification. However, while universal quantification was used to create sentences that are true for all x, existential quantification is used to create sentences that are true for at least one x. It is expressed using the symbol $\exists$. For example, the sentence $\exists x. House(x) \wedge BelongsTo(Minerva, x)$ means that there is at least one symbol that is both a house and that Minerva belongs to it. In other words, this expresses the idea that Minerva belongs to a house.</p><p>Existential and universal quantification can be used in the same sentence. For example, the sentence $\forall x. Person(x) \rightarrow (\forall y. House(y) \wedge BelongsTo(x, y))$ expresses the idea that if $x$ is a person, then there is at least one house, $ y$ , to which this person belongs. In other words, this sentence means that every person belongs to a house.</p><p>There are other types of logic as well, and the commonality between them is that they all exist in pursuit of representing information. These are the systems we use to represent knowledge in our AI.</p>]]></content>
      
      
      <categories>
          
          <category> Artificial Intelligence </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Artificial Intelligence </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Intro to AI Chapter 1 Search</title>
      <link href="/2022/02/18/Intro-to-AI-Chapter-1-Search/"/>
      <url>/2022/02/18/Intro-to-AI-Chapter-1-Search/</url>
      
        <content type="html"><![CDATA[<h1>Chapter 1  Search</h1><h2 id="Some-Terminology">Some Terminology</h2><ul><li><p>agent:<br><strong>Entity</strong> that perceives its environment (is able to perceive something around it) and acts upon that environment in some way.</p></li><li><p>state:<br><strong>Just some figuration</strong> of the agent in its environment.</p></li><li><p>initial state:<br>One such state where <strong>we are going to start from</strong>, the starting point of search algorithm.</p></li><li><p>actions:<br>Choices  that can be made in a state.<br>We are going to effectively define a function called actions.<br><strong>Actions(s)</strong> returns <strong>the set of all actions</strong> that can be executed in state s.<br>Only valid in certain states, like s.</p></li><li><p>transition model:<br>A description of what state results from performing any applicable action in any state. Focusing on how it is that <strong>states and actions are related to each other</strong>.<br>Define as a function. <strong>Result(s, a)</strong> returns the state resulting from performing action a in state s. <strong>2 inputs, state s and action a.</strong></p></li><li><p>state space<br><strong>The set of all states</strong> reachable from the initial state by any sequence of actions.<br>Simplified to a directed graph, the nodes represent one of the state and the edges represent the actions we can take in any particular state.</p></li><li><p>goal test<br>Way to determine whether a given state is a <strong>goal state</strong>.</p></li><li><p>path cost<br>Numerical cost associated with a given path. Let AI find <strong>the minimum path cost</strong>.</p></li></ul><h2 id="Graph-Searching">Graph Searching</h2><ul><li><p>stack<br>A data structure that is last-in first-out.<br>Applied in DFS algorithm.</p></li><li><p>queue<br>A data structure that is a first-in first-out.<br>Applied in BFS(Breadth first searching) algorithm.</p></li></ul><h2 id="Improment">Improment</h2><ul><li><p>uninformed search<br>Search strategy that uses no problem-specific knowledge.<br>Based on BFS and DFS algorithm, no need to care about where the final destination is.</p></li><li><p>informed search<br>Search strategy that uses problem-specific knowledge to find soulutions more effectively.</p></li></ul><h3 id="Improved-algorithm-on-BFS-DFS">Improved algorithm on BFS &amp; DFS</h3><ul><li>greedy best-first search (GBFS)<br>Search algorithmn that expands the node that is cloest to the goal, as estimated by a heuristic function <em><strong>h(n)</strong></em><br><em><strong>Why is greedy?</strong></em> It’s only making the best desition, locally.</li></ul><blockquote><p><strong>Manhattan Distance</strong><br>One specific type od heurstic, only veetically and horizontally allowed, to calculate the distance and comapare.</p></blockquote><ul><li>A* search<br>Search algorithm that expands node with lowest value of <em><strong>g(n) + h(n)</strong></em><br><em><strong>h(n)</strong></em> is the estimated cost to goal, equal to that in GBFS.<br><em><strong>g(n)</strong></em> is the cost to reach node, which means how many steps that I have to take in order to get to the current position.</li></ul><blockquote><p><strong>Optimal Only If</strong></p></blockquote><ol><li><em><strong>h(n)</strong></em> is admissible (never overestimate the true cost)</li><li><em><strong>h(n)</strong></em> is consistent (for every node <strong>n</strong>, and successor <strong>n’</strong> with step cost <strong>c</strong>, <em><strong>h(n) ≤ h(n’) + c</strong></em>. The distance you except must be shorter than the actual distance, or just equal to the actual distance. In this way we call that <strong>h(x)</strong> is admissable and optimistic.</li></ol><h2 id="Adversarial-Search">Adversarial Search</h2><ul><li>Minimax (recursive algorithm)<br>The situation is defined in a tic-tac-toe game. The final result of the game has been reduced mathematically to just this idea of, try and maximaze the score. X player wants the score be higher, O player wants the score be lower as possible.<br><em><strong>MAX(X)</strong></em> : maximize the score that <em>X</em> will get.<br><em><strong>MIN(O)</strong></em> : minimize the score that <em>O</em> will get.</li></ul><blockquote><p><strong>A Determination of the Game Rules</strong><br>If O player win the game, the final result of the game is <strong>-1</strong>, by contrary, the result is <strong>1</strong> if O player win the game; the result will be <strong>0</strong> if neither of 2 players win the game.</p></blockquote><blockquote><p><strong>Functions</strong></p></blockquote><ol><li>$ S_{0} $: initial state.</li><li>PLAYER(s): returns which player to move in state s.</li><li>ACTIONS(s): returns legal moves in state s.</li><li>RESULTS(s, a): returns stater after actions a taken in state s.</li><li>TERMINAL(s): checks if state s is a terminal state.</li><li>UTILITY(s): final numerical value for terminal state s.</li></ol><p>Given a state <strong>s</strong>:</p><ul><li>MAX picks action <em><strong>a</strong></em> in <em><strong>ACTIONS(s)</strong></em> that produces highest value of <em><strong>MIN-VALUE(RESULT(s, a))</strong></em>.</li><li>MIN picks action <em><strong>a</strong></em> in <em><strong>ACTIONS(s)</strong></em> that produces smallest value of <em><strong>MAX-VALUE(RESULT(s, a))</strong></em>.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">functiuon MAX_VALUE(state):</span><br><span class="line">    <span class="keyword">if</span> TERMINAL(state):</span><br><span class="line">        <span class="keyword">return</span> UTILITY(state) </span><br><span class="line">        <span class="comment"># the utility function just knows what the value is</span></span><br><span class="line">    v = -∞  </span><br><span class="line">    <span class="comment"># the value of the state, the initial value is as small as possible</span></span><br><span class="line">    <span class="keyword">for</span> action <span class="keyword">in</span> ACTIONS(state):</span><br><span class="line">        v = MAX(v, MIN_VALUE(RESULT(action, state)))</span><br><span class="line">    <span class="keyword">return</span> v</span><br><span class="line"></span><br><span class="line">function MIN_VALUE(state):</span><br><span class="line">    <span class="keyword">if</span> TERMINAL(state):</span><br><span class="line">        <span class="keyword">return</span> UTILITY(state) </span><br><span class="line">        <span class="comment"># the utility function just knows what the value is</span></span><br><span class="line">    v = ∞  </span><br><span class="line">    <span class="comment"># the value of the state, the initial value is as big as possible</span></span><br><span class="line">    <span class="keyword">for</span> action <span class="keyword">in</span> ACTIONS(state):</span><br><span class="line">        v = MIN(v, MIN_VALUE(RESULT(action, state)))</span><br><span class="line">    <span class="keyword">return</span> v</span><br></pre></td></tr></table></figure><p>Figure out what the best move to make is by recursively using these maxValue and minValue, maxValue calls minValue, minValue calls maxValue, back and forth, all the way until we reach a terminal state, at which our algorithm can simply return the utiliyu of that particular state.</p><h3 id="Improved-algorithm-on-adversarial-search">Improved algorithm on adversarial search</h3><ul><li><p>Alpha-Beta Pruning<br>When there is a sub-selection with a lower or higher score than the Alpha-choice appears in the Beta-choice, abandon the exploration of the remaining sub-selection in the Beta-choice. It depends on either you are a value-maximized player or a valur-minimized player.</p></li><li><p>Depth-Limited Minimax<br>Minimax algorithm atarts with an initial state, cosiders all the possible actions and all the possible actions after that.</p></li></ul><blockquote><p><em><strong>An added new function</strong></em><br><strong>evaluation funtion</strong><br>Function that estimated the expected utility of the game from a given state.</p></blockquote><p>When there are too many choices to obtain results at an acceptable cost(time or space), then approximately limit the number of depth levels.</p>]]></content>
      
      
      <categories>
          
          <category> Artificial Intelligence </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Artificial Intelligence </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
